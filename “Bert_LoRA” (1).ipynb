{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "# 挂载Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hLu5lDiOC-7X",
    "outputId": "e070619f-6855-4ae2-909c-aaa370b112e3"
   },
   "id": "hLu5lDiOC-7X",
   "execution_count": 23,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install datasets"
   ],
   "metadata": {
    "id": "FevpuHKDC2CD",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "5a7c6f35-53c0-47b1-b267-6e51e088d047"
   },
   "id": "FevpuHKDC2CD",
   "execution_count": 24,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.19.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.14.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
      "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.4)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.23.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a63994ce-83d1-4c84-b372-2a1b6167f90a",
   "metadata": {
    "id": "a63994ce-83d1-4c84-b372-2a1b6167f90a"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import pandas as pd\n",
    "import os\n",
    "from transformers import AutoTokenizer\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from transformers import default_data_collator, get_linear_schedule_with_warmup\n",
    "from tqdm import tqdm\n",
    "from datasets import load_dataset, Dataset\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 载入数据"
   ],
   "metadata": {
    "id": "xxcBFXkcEHoq"
   },
   "id": "xxcBFXkcEHoq"
  },
  {
   "cell_type": "code",
   "source": [
    "# 定义TXT文件路径\n",
    "file_path_true = \"/content/drive/My Drive/fake news/test_nonrumor.txt\"  # 真信息数据集\n",
    "file_path_fake = \"/content/drive/My Drive/fake news/test_rumor.txt\"  # 假信息数据集\n",
    "\n",
    "# 读取TXT文件并转换为列表\n",
    "with open(file_path_true, 'r', encoding='utf-8') as f:\n",
    "    data_true = f.read().splitlines()\n",
    "\n",
    "with open(file_path_fake, 'r', encoding='utf-8') as f:\n",
    "    data_fake = f.read().splitlines()\n",
    "\n",
    "# 为真信息和假信息创建带标签的DataFrame\n",
    "df_true = pd.DataFrame({'text': data_true, 'label': 'true'})\n",
    "df_fake = pd.DataFrame({'text': data_fake, 'label': 'fake'})\n",
    "\n",
    "# 合并数据集\n",
    "df = pd.concat([df_true, df_fake], ignore_index=True)\n",
    "\n",
    "# 创建Hugging Face datasets对象\n",
    "dataset = Dataset.from_pandas(df)"
   ],
   "metadata": {
    "id": "_qkqm_kVF0Ub"
   },
   "id": "_qkqm_kVF0Ub",
   "execution_count": 26,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "text_column = \"text\"\n",
    "label_column = \"type\"\n",
    "max_length = 640\n",
    "lr = 0.01\n",
    "num_epochs = 10\n",
    "batch_size = 32"
   ],
   "metadata": {
    "id": "3p7CXIAYESzk"
   },
   "id": "3p7CXIAYESzk",
   "execution_count": 27,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import math\n",
    "from typing import List, Tuple\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class LinearLoRA(nn.Module):\n",
    "    \"\"\"\n",
    "    A low-rank adapted linear layer.\n",
    "\n",
    "    Args:\n",
    "        in_dim: int = An integer representing the input dimension of the linear layer\n",
    "        out_dim: int = An integer representing the output dimension of the linear layer\n",
    "        r: int = An integer representing the rank of the low-rank approximated matrices\n",
    "        lora_alpha: int = An integer representing the numerator of the scaling constant alpha / r\n",
    "        lora_dropout: float = A float between 0 and 1 representing the dropout probability\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_dim: int,\n",
    "        out_dim: int,\n",
    "        r: int = 8,\n",
    "        lora_alpha: int = 16,\n",
    "        lora_dropout: float = 0.,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.r = r\n",
    "        self.lora_alpha = lora_alpha\n",
    "        self.lora_dropout = nn.Dropout(lora_dropout)\n",
    "\n",
    "        # Check that the rank is at least 1\n",
    "        assert r > 0, \"Variable 'r' is not greater than zero. Choose a rank of 1 or greater.\"\n",
    "\n",
    "        # recreate the linear layer and freeze it (the actual weight values will be copied in outside of this class)\n",
    "        self.pretrained = nn.Linear(in_dim, out_dim, bias=True)\n",
    "        self.pretrained.weight.requires_grad = False\n",
    "\n",
    "        # create the low-rank A matrix and initialize with same method as in Hugging Face PEFT library\n",
    "        self.lora_A = nn.Linear(in_dim, r, bias=False)\n",
    "        nn.init.kaiming_uniform_(self.lora_A.weight, a=math.sqrt(5))\n",
    "\n",
    "        # create the low-rank B matrix and initialize to zero\n",
    "        self.lora_B = nn.Linear(r, out_dim, bias=False)\n",
    "        nn.init.constant_(self.lora_B.weight, 0)\n",
    "\n",
    "        # scaling constant\n",
    "        self.scaling = self.lora_alpha / self.r\n",
    "\n",
    "    def forward(self, x):\n",
    "        pretrained_out = self.pretrained(x)\n",
    "        lora_out = self.lora_dropout(x)\n",
    "        lora_out = self.lora_A(lora_out)\n",
    "        lora_out = self.lora_B(lora_out)\n",
    "        lora_out = lora_out * self.scaling\n",
    "        return pretrained_out + lora_out\n",
    "\n",
    "\n",
    "def freeze_model(model):\n",
    "    \"\"\"Freezes all layers except the LoRa modules and classifier.\"\"\"\n",
    "    for name, param in model.named_parameters():\n",
    "        if \"lora\" not in name and \"classifier\" not in name:\n",
    "            param.requires_grad = False\n",
    "\n",
    "\n",
    "def create_lora(module, r, lora_dropout, lora_alpha):\n",
    "    \"\"\"Converts a linear module to a LoRA linear module.\"\"\"\n",
    "    k, d = module.weight.shape  # pytorch nn.Linear weights are transposed, that is why shape is (k, d) and not (d, k)\n",
    "    lora = LinearLoRA(d, k, r, lora_dropout=lora_dropout, lora_alpha=lora_alpha)\n",
    "    with torch.no_grad():\n",
    "        lora.pretrained.weight.copy_(module.weight)\n",
    "        lora.pretrained.bias.copy_(module.bias)\n",
    "    return lora\n",
    "\n",
    "\n",
    "def add_lora_layers(\n",
    "    model,\n",
    "    module_names: Tuple=(\"query\", \"value\"),\n",
    "    r: int=8,\n",
    "    lora_alpha: float=16,\n",
    "    lora_dropout: float=0.1,\n",
    "    ignore_layers: List[int]=[]\n",
    "):\n",
    "    \"\"\"\n",
    "        Replaces chosen linear modules with LoRA equivalents.\n",
    "\n",
    "        Args:\n",
    "            model: torch.nn.Module = The PyTorch model to be used\n",
    "            module_names: Tuple = A tuple containing the names of the linear layers to replace\n",
    "                Ex. (\"query\") to replace the linear modules with \"query\" in the name --> bert.encoder.layer.0.attention.self.query\n",
    "            r: int =\n",
    "            lora_alpha: int = An integer representing the numerator of the scaling constant alpha / r\n",
    "            lora_dropout: float = A float between 0 and 1 representing the dropout probability\n",
    "            ignore_layers: list = A list with the indices of all BERT layers NOT to add LoRA modules\n",
    "        \"\"\"\n",
    "    module_types: Tuple=(nn.Linear,)\n",
    "\n",
    "    # disable dropout in frozen layers\n",
    "    for module in model.modules():\n",
    "        if isinstance(module, nn.Dropout):\n",
    "            module.p = 0.0\n",
    "    # replace chosen linear modules with lora modules\n",
    "    for name, module in model.named_children():\n",
    "        if isinstance(module, module_types) and name in module_names:\n",
    "            temp_lora = create_lora(module, r=r, lora_dropout=lora_dropout, lora_alpha=lora_alpha)\n",
    "            setattr(model, name, temp_lora)\n",
    "        else:\n",
    "            ignore_layers_str = [str(i) for i in ignore_layers]\n",
    "            if name not in ignore_layers_str:\n",
    "                add_lora_layers(module, module_names, r, lora_dropout, lora_alpha, ignore_layers)\n",
    "\n",
    "\n",
    "def unfreeze_model(model):\n",
    "    \"\"\"Unfreezes all parameters in a model by setting requires_grad to True.\"\"\"\n",
    "    for name, param in model.named_parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "\n",
    "def create_linear(module):\n",
    "    \"\"\"Converts a LoRA linear module back to a linear module.\"\"\"\n",
    "    k, d = module.pretrained.weight.shape  # pytorch nn.Linear weights are transposed, that is why variables are k, d and not d, k\n",
    "    linear = nn.Linear(d, k, bias=True)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        linear.weight.copy_(module.pretrained.weight + (module.lora_B.weight @ module.lora_A.weight) * module.scaling)\n",
    "        linear.bias.copy_(module.pretrained.bias)\n",
    "\n",
    "    return linear\n",
    "\n",
    "\n",
    "def merge_lora_layers(model, module_names: Tuple=(\"query\", \"value\"), dropout=0.1):\n",
    "    \"\"\"\n",
    "        Replaces LoRA modules with their original linear equivalents.\n",
    "\n",
    "        Args:\n",
    "            model: torch.nn.Module = The PyTorch model to be used\n",
    "            module_names: Tuple = A tuple containing the names of the LoRA layers to replace\n",
    "                Ex. (\"query\") to replace the LoRA modules with \"query\" in the name --> bert.encoder.layer.0.attention.self.query\n",
    "            r: int =\n",
    "            dropout: float = A float between 0 and 1 representing the dropout probability\n",
    "        \"\"\"\n",
    "    # enable dropout in frozen layers\n",
    "    for module in model.modules():\n",
    "        if isinstance(module, nn.Dropout):\n",
    "            module.p = dropout\n",
    "    # replace chosen linear modules with lora modules\n",
    "    for name, module in model.named_children():\n",
    "        if name in module_names and hasattr(module, \"pretrained\"):\n",
    "            temp_linear = create_linear(module)\n",
    "            setattr(model, name, temp_linear)\n",
    "        else:\n",
    "            merge_lora_layers(module, module_names=module_names, dropout=0.1)\n"
   ],
   "metadata": {
    "id": "vKY0_UPIOOj0"
   },
   "id": "vKY0_UPIOOj0",
   "execution_count": 28,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install transformers\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ca1BsOQAWXAe",
    "outputId": "cacd48a3-b100-4ca9-bd5d-e75a7eefc5d7"
   },
   "id": "Ca1BsOQAWXAe",
   "execution_count": 29,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.40.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.14.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from transformers import BertPreTrainedModel, BertModel, BertConfig\n",
    "from torch import nn\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "\n",
    "\n",
    "class BertForSequenceClassificationWithLoRA(BertPreTrainedModel):\n",
    "    def __init__(self, config, lora_config=None, pretrained_model=None):\n",
    "        super().__init__(config)\n",
    "        if pretrained_model is None:\n",
    "            self.bert = BertModel(config)\n",
    "        else:\n",
    "            self.bert = pretrained_model\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "\n",
    "        # 假设lora_config包含了LoRA所需的配置\n",
    "        self.classifier = (\n",
    "            LinearLoRA(config.hidden_size, config.num_labels, **lora_config)\n",
    "            if lora_config\n",
    "            else nn.Linear(config.hidden_size, config.num_labels)\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids: torch.Tensor, attention_mask: torch.Tensor) -> torch.Tensor:\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.last_hidden_state[:, 0]\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "        return logits\n",
    "\n",
    "    # 添加一个辅助方法来加载预训练模型并替换分类器\n",
    "    @classmethod\n",
    "    def from_pretrained_with_lora(cls, model_name, num_labels, lora_config=None, **kwargs):\n",
    "        config = BertConfig.from_pretrained(model_name, **kwargs)\n",
    "        pretrained_model = BertModel.from_pretrained(model_name, **kwargs)\n",
    "        model = cls(config, lora_config=lora_config, pretrained_model=pretrained_model)\n",
    "        return model\n",
    "\n",
    "# 使用示例\n",
    "lora_config = {'r': 8}  # 假设的LoRA配置\n",
    "model = BertForSequenceClassificationWithLoRA.from_pretrained_with_lora(\"bert-base-uncased\", num_labels=2, lora_config=lora_config)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DOxXX4WkY9y-",
    "outputId": "e261b67b-7d17-4834-d596-f2d92773951b"
   },
   "id": "DOxXX4WkY9y-",
   "execution_count": 30,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import torch\n",
    "\n",
    "# 假设你有一个简单的Dataset类\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, input_ids, attention_mask, labels):\n",
    "        self.input_ids = input_ids\n",
    "        self.attention_mask = attention_mask\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {'input_ids': self.input_ids[idx], 'attention_mask': self.attention_mask[idx], 'labels': self.labels[idx]}\n",
    "\n",
    "# 示例数据（这里仅用于说明，您应该用实际的数据替代）\n",
    "# 假设每个样本是32个token IDs\n",
    "input_ids = torch.randint(0, 100, (6000, 32))  # 6000个样本，每个样本32个token IDs\n",
    "attention_mask = torch.ones(6000, 32, dtype=torch.long)  # 6000个样本，每个样本32个token的attention mask，全为1表示没有padding\n",
    "labels = torch.randint(0, 2, (6000,))  # 6000个样本的标签\n",
    "\n",
    "# 创建Dataset实例\n",
    "dataset = MyDataset(input_ids, attention_mask, labels)\n",
    "\n",
    "# 创建DataLoader实例\n",
    "batch_size = 32\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# 现在你可以在你的evaluate函数中使用这个dataloader了\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def evaluate(model, dataloader, device):\n",
    "    model.eval()\n",
    "    model.to(device)  # 确保模型被移动到了正确的设备上\n",
    "    total_preds = []\n",
    "    total_labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            # 假设outputs.logits是模型最后一层的输出\n",
    "            # 注意：不同的模型可能有不同的输出结构，这里需要根据你的模型来调整\n",
    "            if isinstance(outputs, tuple):  # 如果模型输出是一个元组（例如包含logits和losses）\n",
    "                logits = outputs[0]\n",
    "            else:  # 如果模型输出直接就是logits\n",
    "                logits = outputs\n",
    "            _, preds = torch.max(logits, dim=1)\n",
    "            total_preds.extend(preds.cpu().numpy())\n",
    "            total_labels.extend(labels.cpu().numpy())\n",
    "    return total_preds, total_labels\n",
    "\n",
    "# 首先确定设备\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "# 现在你可以调用evaluate函数，并传入device\n",
    "total_preds, total_labels = evaluate(model, dataloader, device)\n",
    "\n",
    "# 计算准确率和报告（确保你已经导入了相关的库）\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "accuracy = accuracy_score(total_labels, total_preds)\n",
    "report = classification_report(total_labels, total_preds)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(report)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I1C_oxptZNMA",
    "outputId": "39d6ca41-f2ef-4524-d923-51660537ad2f"
   },
   "id": "I1C_oxptZNMA",
   "execution_count": 43,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy: 0.49983333333333335\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67      3001\n",
      "           1       0.46      0.00      0.01      2999\n",
      "\n",
      "    accuracy                           0.50      6000\n",
      "   macro avg       0.48      0.50      0.34      6000\n",
      "weighted avg       0.48      0.50      0.34      6000\n",
      "\n"
     ]
    }
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
